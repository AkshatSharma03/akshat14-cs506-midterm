{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading data...\n","Preprocessing data...\n"]},{"name":"stderr","output_type":"stream","text":["Processing Summary: 100%|██████████| 848766/848766 [00:45<00:00, 18455.88it/s]\n","Processing Text: 100%|██████████| 848766/848766 [14:57<00:00, 945.70it/s] \n","Processing Summary: 100%|██████████| 212192/212192 [00:01<00:00, 205107.41it/s]\n","Processing Text: 100%|██████████| 212192/212192 [00:01<00:00, 205673.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Engineering features...\n","Engineering features...\n","Cleaning target variable...\n","Splitting data...\n","Performing TF-IDF vectorization...\n","Training XGBoost model...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/homebrew/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [14:12:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Making predictions on validation set...\n","Validation Accuracy: 0.6006301799648553\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.59      0.42      0.49      9186\n","           1       0.39      0.09      0.15      8887\n","           2       0.47      0.14      0.22     17568\n","           3       0.44      0.20      0.27     33546\n","           4       0.63      0.95      0.76     79342\n","\n","    accuracy                           0.60    148529\n","   macro avg       0.50      0.36      0.38    148529\n","weighted avg       0.55      0.60      0.53    148529\n","\n","Preparing test data...\n","Making predictions on test set...\n","Creating submission file...\n","Submission file created successfully.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","from scipy.sparse import hstack\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","import re\n","from tqdm import tqdm\n","\n","# Enable tqdm for pandas\n","tqdm.pandas()\n","\n","# Download necessary NLTK data\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","# Load the data\n","print(\"Loading data...\")\n","train_df = pd.read_csv('/Users/akshatsharma/Downloads/CS506 Midterm Fall 2024 (1)/train.csv')\n","test_df = pd.read_csv('/Users/akshatsharma/Downloads/CS506 Midterm Fall 2024 (1)/test.csv')\n","\n","# Reduce dataset size for faster processing\n","train_df = train_df.sample(frac=0.5, random_state=42)\n","\n","# Preprocess text\n","stop_words = set(stopwords.words('english'))\n","ps = PorterStemmer()\n","\n","def preprocess_text(text):\n","    if pd.isna(text):\n","        return \"\"\n","    text = re.sub('<[^<]+?>', '', str(text))\n","    text = text.lower()\n","    tokens = word_tokenize(text)\n","    tokens = [ps.stem(word) for word in tokens if word not in stop_words]\n","    return ' '.join(tokens)\n","\n","print(\"Preprocessing data...\")\n","for df in [train_df, test_df]:\n","    for col in ['Summary', 'Text']:\n","        if col not in df.columns:\n","            df[col] = ''\n","        tqdm.pandas(desc=f\"Processing {col}\")\n","        df[f'processed_{col.lower()}'] = df[col].progress_apply(preprocess_text)\n","\n","# Feature engineering\n","def engineer_features(df):\n","    print(\"Engineering features...\")\n","    for col in ['HelpfulnessNumerator', 'HelpfulnessDenominator']:\n","        if col not in df.columns:\n","            df[col] = 0\n","    df['helpfulness_ratio'] = df['HelpfulnessNumerator'] / (df['HelpfulnessDenominator'] + 1)\n","    df['text_length'] = df['Text'].fillna('').str.len().astype('int32')\n","    df['caps_ratio'] = df['Text'].fillna('').apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n","    df['exclamation_count'] = df['Text'].fillna('').str.count('!')\n","    return df\n","\n","train_df = engineer_features(train_df)\n","test_df = engineer_features(test_df)\n","\n","# Clean the target variable\n","print(\"Cleaning target variable...\")\n","train_df = train_df.dropna(subset=['Score'])\n","train_df['Score'] = train_df['Score'].astype(int)\n","\n","# Prepare features and target\n","features = ['helpfulness_ratio', 'text_length', 'caps_ratio', 'exclamation_count']\n","X = train_df[features].astype('float32')\n","y = train_df['Score'] - 1  # Adjust scores to start from 0\n","train_text = train_df['processed_text']\n","\n","# Split the data\n","print(\"Splitting data...\")\n","X_train, X_val, y_train, y_val, train_text, val_text = train_test_split(\n","    X, y, train_text, test_size=0.2, random_state=42\n",")\n","\n","# TF-IDF vectorization\n","print(\"Performing TF-IDF vectorization...\")\n","tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n","X_train_tfidf = tfidf.fit_transform(train_text)\n","X_val_tfidf = tfidf.transform(val_text)\n","\n","# Combine features\n","X_train_combined = hstack((X_train_tfidf, X_train)).tocsr()\n","X_val_combined = hstack((X_val_tfidf, X_val)).tocsr()\n","\n","# Train XGBoost model\n","print(\"Training XGBoost model...\")\n","xgb_model = XGBClassifier(\n","    n_estimators=100,\n","    max_depth=6,\n","    learning_rate=0.1,\n","    random_state=42,\n","    use_label_encoder=False,\n","    eval_metric=\"mlogloss\",\n","    n_jobs=-1  # Use all available cores\n",")\n","xgb_model.fit(X_train_combined, y_train)\n","\n","# Make predictions on validation set\n","print(\"Making predictions on validation set...\")\n","y_pred = xgb_model.predict(X_val_combined)\n","\n","# Calculate accuracy and other metrics\n","accuracy = accuracy_score(y_val, y_pred)\n","print(f\"Validation Accuracy: {accuracy}\")\n","print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n","\n","# Prepare test data\n","print(\"Preparing test data...\")\n","X_test = test_df[features].astype('float32')\n","X_test_tfidf = tfidf.transform(test_df['processed_text'])\n","X_test_combined = hstack((X_test_tfidf, X_test)).tocsr()\n","\n","# Make predictions on test set\n","print(\"Making predictions on test set...\")\n","test_predictions = xgb_model.predict(X_test_combined)\n","\n","# Prepare submission file\n","print(\"Creating submission file...\")\n","submission = pd.DataFrame({'Id': test_df['Id'], 'Score': test_predictions + 1})  # Add 1 to shift back to original score range\n","submission.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file created successfully.\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9926464,"sourceId":87299,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
